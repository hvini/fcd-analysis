{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"lh\": {\n",
    "        \"aparc\": {\n",
    "            \"volume\": \"../stats/aparc/lh/aparc/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/lh/aparc/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/lh/aparc/meancurv_stats.csv\"\n",
    "        },\n",
    "        \"a2009s\": {\n",
    "            \"volume\": \"../stats/aparc/lh/aparc.a2009s/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/lh/aparc.a2009s/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/lh/aparc.a2009s/meancurv_stats.csv\"\n",
    "        },\n",
    "        \"pial\": {\n",
    "            \"volume\": \"../stats/aparc/lh/aparc.pial/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/lh/aparc.pial/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/lh/aparc.pial/meancurv_stats.csv\"\n",
    "        }\n",
    "    },\n",
    "    \"rh\": {\n",
    "        \"aparc\": {\n",
    "            \"volume\": \"../stats/aparc/rh/aparc/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/rh/aparc/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/rh/aparc/meancurv_stats.csv\"\n",
    "        },\n",
    "        \"a2009s\": {\n",
    "            \"volume\": \"../stats/aparc/rh/aparc.a2009s/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/rh/aparc.a2009s/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/rh/aparc.a2009s/meancurv_stats.csv\"\n",
    "        },\n",
    "        \"pial\": {\n",
    "            \"volume\": \"../stats/aparc/rh/aparc.pial/volume_stats.csv\",\n",
    "            \"thickness\": \"../stats/aparc/rh/aparc.pial/thickness_stats.csv\",\n",
    "            \"meancurv\": \"../stats/aparc/rh/aparc.pial/meancurv_stats.csv\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "participants_file = \"../ds004199/participants.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \n",
    "    def __init__(self, file_paths, participants_file, v=False):\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.__logger = logging.getLogger(__name__)\n",
    "\n",
    "        self.__verbose = v\n",
    "\n",
    "        self.__file_paths = file_paths\n",
    "        self.__participants_file = participants_file\n",
    "\n",
    "        self.__final_data = None\n",
    "\n",
    "\n",
    "    def get_final_data(self):\n",
    "        \"\"\"Returns the final processed data.\"\"\"\n",
    "\n",
    "        return self.__final_data\n",
    "    \n",
    "    def _reads_n_standardizes(self, file_path):\n",
    "        \"\"\"Reads a CSV file and standardizes column names.\"\"\"\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns.values[0] = 'subject'\n",
    "        df.columns = [col.replace('-', '_').lower() for col in df.columns]\n",
    "        return df\n",
    "    \n",
    "    def _rename_columns(self, df, hemisphere, parcellation, measure):\n",
    "        \"\"\"Renames the columns based on hemisphere, parcellation, and measure.\"\"\"\n",
    "\n",
    "        match parcellation:\n",
    "            case \"aparc\":\n",
    "                df.columns = [df.columns[0]] + [f\"{col}_{measure}_{hemisphere}\" for col in df.columns[1:]]\n",
    "            case _:\n",
    "                df.columns = [df.columns[0]] + [f\"{col}_{measure}_{hemisphere}_{parcellation}\" for col in df.columns[1:]]\n",
    "        return df\n",
    "    \n",
    "    def _merge_hemisphere_data(self, hemisphere_data, hemisphere):\n",
    "        \"\"\"Merges data for a given hemisphere across multiple parcellations and measures.\"\"\"\n",
    "\n",
    "        dfs = []\n",
    "        for parcellation, measures in hemisphere_data.items():\n",
    "            for measure, file_path in measures.items():\n",
    "                if self.__verbose: self.__logger.info(f\"Loading {file_path} for {measure} in {parcellation}\")\n",
    "                df = self._reads_n_standardizes(file_path)\n",
    "                df = self._rename_columns(df, hemisphere, parcellation, measure)\n",
    "                dfs.append(df)\n",
    "        \n",
    "        final_df = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            final_df = pd.merge(final_df, df, on='subject')\n",
    "        return final_df\n",
    "\n",
    "    def _load_and_merge_hemisphere_data(self, hemisphere):\n",
    "        \"\"\"Loads and merges data for a single hemisphere (left or right).\"\"\"\n",
    "\n",
    "        hemisphere_data = self.__file_paths[hemisphere]\n",
    "        return self._merge_hemisphere_data(hemisphere_data, hemisphere)\n",
    "    \n",
    "    def _load_participant_data(self):\n",
    "        \"\"\"Loads the participants data and returns the group column.\"\"\"\n",
    "\n",
    "        participants = pd.read_csv(self.__participants_file, sep=\"\\t\")\n",
    "        group = participants[[\"participant_id\", \"group\"]]\n",
    "        return group\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Main method to process all data, including merging left and right hemisphere data, aseg data, and participants.\"\"\"\n",
    "        \n",
    "        lh_data = self._load_and_merge_hemisphere_data(\"lh\")\n",
    "        rh_data = self._load_and_merge_hemisphere_data(\"rh\")\n",
    "        \n",
    "        self.__final_data = pd.merge(lh_data, rh_data, on='subject')\n",
    "\n",
    "        aseg_data = self._reads_n_standardizes(\"../stats/aseg_stats.csv\")\n",
    "        self.__final_data = pd.merge(self.__final_data, aseg_data, on='subject')\n",
    "\n",
    "        group = self._load_participant_data()\n",
    "        self.__final_data = pd.merge(self.__final_data, group, left_on='subject', right_on='participant_id')\n",
    "\n",
    "        self.__final_data.drop(columns=['participant_id'], inplace=True)\n",
    "\n",
    "    def save_data(self, file_path):\n",
    "        \"\"\"Saves the final processed data to a CSV file.\"\"\"\n",
    "\n",
    "        self.__final_data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataProcessor(file_paths, participants_file, v=True)\n",
    "processor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = processor.get_final_data()\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_data(\"../stats/merged_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
